{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vr5VeayidpzH"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMJyTN41mek9vzX5DsspDUO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoOnger/BSP_Project/blob/main/BSP_ECG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BSP Project: ECG signal decomposition using Fourier analysis**\n",
        "\n",
        "*   **Author:** Matteo Onger\n",
        "*   **Date:** February 2025"
      ],
      "metadata": {
        "id": "v0ctyAMTGTJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Documentation**:\n",
        "*   Paper: [ECG signal decomposition using Fourier analysis](https://doi.org/10.1186/s13634-024-01171-x)\n",
        "*   Dataset: [Lobachevsky University Electrocardiography Database](https://www.physionet.org/content/ludb/1.0.1/)\n",
        "*   Python packages: [WFDB](https://pypi.org/project/wfdb/)\n",
        "\n",
        "**Notes**:\n",
        "*   For faster execution, please use a gpu-equipped runtime."
      ],
      "metadata": {
        "id": "U6C2Fh1zGtyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install library\n",
        "!pip install wfdb\n",
        "\n",
        "# download repository\n",
        "!git clone -b main https://github.com/MatteoOnger/BSP_Project.git"
      ],
      "metadata": {
        "id": "sA_FA_El_Lc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- LIBRARIES ----\n",
        "import importlib\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import wfdb.processing as wfdb_proc\n",
        "\n",
        "from typing import Literal\n",
        "\n",
        "from BSP_Project.rbfuncs import GaussianRBF, RadialBasisFunc\n",
        "from BSP_Project.signals import ECG\n",
        "\n",
        "\n",
        "# set logger\n",
        "logging.basicConfig(format=\"%(asctime)s | %(levelname)s | %(name)s:%(funcName)s - %(message)s\", level=logging.INFO, force=True)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# current runtime type, if gpu available use cupy else numpy\n",
        "if os.environ[\"COLAB_GPU\"] != \"\":\n",
        "    GPU = True\n",
        "    logger.info(\"GPU connected\")\n",
        "    logger.info(\"Load Cupy\")\n",
        "    ncp = importlib.import_module(\"cupy\")\n",
        "else:\n",
        "    GPU = False\n",
        "    logger.info(\"No accelerator connected\")\n",
        "    ncp = np"
      ],
      "metadata": {
        "id": "8pCTkTyLLE-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- FUNCTIONS ----\n",
        "def dft_l1(x :ncp.ndarray, K :int, max_iters :int=5, eps :float|None=1e-6, fast_init :bool=True) -> ncp.ndarray:\n",
        "    \"\"\"\n",
        "    Computes the l1 Fourier transform of a real signal ``x`` and returns the Fourier coefficients.\n",
        "    The parameter ``K`` determines the number of Fourier coefficients to compute, so,\n",
        "    if it is not equal to the length of ``x``, a truncated l1 Fourier trasform is computed.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : numpy.ndarray | cupy.ndarray of shape \\(N)\n",
        "        Original signal, i.e. an array of ``N`` real numbers that are the samples collected.\n",
        "    K : int\n",
        "        Number of Fourier coefficients to compute.\n",
        "    max_iters : int, optional\n",
        "        Maximum number of iterations, by default is ``5``.\n",
        "    eps : float | None, optional\n",
        "        Tolerance for the convergence of the algorithm, by default is ``1e-6``.\n",
        "        If ``None``, the algorithm will run until the maximum number of iterations is reached.\n",
        "    fast_init : bool, optional\n",
        "        If ``True``, the algorithm will use a faster initialization of the Fourier coefficients, by default is ``True``.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    : numpy.ndarray | cupy.ndarray of shape \\(K)\n",
        "        The Fourier coefficients computed, i.e. an array of ``K`` complex numbers.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    : ValueError\n",
        "        If ``K != N`` and ``K > 1 + N//2``.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - If the input signal ``x`` contains complex numbers, only the real part is taken into account.\n",
        "    \"\"\"\n",
        "    N = len(x)\n",
        "    if (K != N) and (K > 1 + N//2):\n",
        "        raise ValueError(\"<K> must be equal to the length of <x> or smaller/equal than half the length of <x> plus 1\")\n",
        "\n",
        "    logger.info(f\"Start -> K={K}, max_iters={max_iters}, eps={eps}\")\n",
        "\n",
        "    # if gpu available, move data to the device\n",
        "    isnumpy = isinstance(x, np.ndarray)\n",
        "    if GPU and isnumpy:\n",
        "        x = ncp.asarray(x)\n",
        "\n",
        "    # keep only real part\n",
        "    x = ncp.real(x)\n",
        "\n",
        "    # total number of coefficients computed\n",
        "    # including complex conjugates\n",
        "    M = 2*K - 1 if K != N else K\n",
        "    if (N % 2 == 0) and (K == 1 + N//2):\n",
        "        M -= 1\n",
        "\n",
        "    # fourier basis, matrix of shape (N,M) and its conjugate transpose\n",
        "    fi = ncp.exp(ncp.array([[1j * (2 * ncp.pi * k / N) * n for k in range(K-M, K, 1)] for n in range(N)])) / ncp.sqrt(N)\n",
        "    tconj_fi = ncp.transpose(ncp.conj(fi))\n",
        "\n",
        "    # init fourier coefficients\n",
        "    coeff = ncp.zeros(fi.shape[1], dtype=ncp.complex128)\n",
        "    # reconstructed signal\n",
        "    xk = x + 1 if fast_init else ncp.real(fi @ coeff)\n",
        "    # previously recon. signal\n",
        "    prev_xk = None\n",
        "\n",
        "    for iter in range(max_iters):\n",
        "        delta = ncp.abs(x - xk)\n",
        "        delta = ncp.diag(1 / ncp.where(delta == 0, 1e-18, delta))\n",
        "\n",
        "        # update fourier coefficients and prev. recon. signal and recon. signal\n",
        "        coeff = ncp.linalg.inv(tconj_fi @ delta @ fi) @ tconj_fi @ delta @ x\n",
        "        prev_xk = xk\n",
        "        xk = ncp.real(fi @ coeff)\n",
        "\n",
        "        # check convergency\n",
        "        conv = np.mean(np.abs(xk - prev_xk))\n",
        "        logger.debug(f\"Iteration {iter+1} -> convergency={conv}\")\n",
        "        if (eps is not None) and (conv <= eps):\n",
        "            break\n",
        "\n",
        "    # compute final convergency and loss wrt original signal\n",
        "    conv, loss = np.mean(np.abs(xk - prev_xk)), ncp.abs((x - xk) / np.where(x == 0, 1, x))\n",
        "    logger.info(f\"End -> iter={iter+1}, \" +\n",
        "        f\"convergency={ncp.round(conv, 4)}, \" +\n",
        "        f\"min_abs_loss={ncp.around(ncp.min(loss), 4)}, \"  +\n",
        "        f\"avg_abs_loss={ncp.around(ncp.mean(loss), 4)}, \" +\n",
        "        f\"max_abs_loss={ncp.around(ncp.max(loss), 4)}\"\n",
        "    )\n",
        "    return ncp.asnumpy(coeff[-K:]) if GPU and isnumpy else coeff[-K:]\n",
        "\n",
        "\n",
        "def idft_l1(coeff :ncp.ndarray, N :int, onlyreal :bool=False) -> ncp.ndarray:\n",
        "    \"\"\"\n",
        "    Computes the inverse l1 Fourier transform of a real signal ``x`` given its Fourier coefficients ``coeff``\n",
        "    and returns the reconstructed signal.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    coeff : numpy.ndarray | cupy.ndarray of shape \\(K)\n",
        "        Fourier coefficients, i.e. an array of ``K`` complex numbers.\n",
        "    N : int\n",
        "        Length of the signal to reconstruct.\n",
        "    onlyreal : bool, optional\n",
        "        If ``True``, only the real part of the reconstructed signal is returned, by default is ``False``.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    : numpy.ndarray | cupy.ndarray of shape \\(N)\n",
        "        The reconstructed signal, i.e. an array of ``N`` real numbers.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    : ValueError\n",
        "        If ``K != N`` and ``K > 1 + N//2``.\n",
        "    \"\"\"\n",
        "    K = len(coeff)\n",
        "    if (K != N) and (K > 1 + N//2):\n",
        "        raise ValueError(\"the number of coefficients must be equal to <N> or smaller/equal than <N> half plus 1\")\n",
        "\n",
        "    # if gpu available, move data to the device\n",
        "    isnumpy = isinstance(coeff, np.ndarray)\n",
        "    if GPU and isnumpy:\n",
        "        coeff = ncp.asarray(coeff)\n",
        "\n",
        "    # total number of coefficients computed\n",
        "    # including complex conjugates\n",
        "    M = 2*K - 1 if K != N else K\n",
        "    if (N % 2 == 0) and (K == 1 + N//2):\n",
        "        M -= 1\n",
        "\n",
        "    # fourier basis, matrix of shape (N,M)\n",
        "    fi = ncp.exp(ncp.array([[1j * (2 * ncp.pi * k / N) * n for k in range(K-M, K, 1)] for n in range(N)])) / ncp.sqrt(N)\n",
        "\n",
        "    # if not given, compute conjugate fourier coefficients\n",
        "    if N != K:\n",
        "        if (N % 2 == 0) and (K == 1 + N//2):\n",
        "            coeff = ncp.concatenate((ncp.conj(coeff[1:-1][::-1]), coeff))\n",
        "        else:\n",
        "            coeff = ncp.concatenate((ncp.conj(coeff[1:][::-1]), coeff))\n",
        "\n",
        "    # reconstructed signal\n",
        "    xk = ncp.real(fi @ coeff) if onlyreal else fi @ coeff\n",
        "    return ncp.asnumpy(xk) if GPU and isnumpy else xk\n",
        "\n",
        "\n",
        "def derivatives(x : ncp.ndarray) -> ncp.ndarray:\n",
        "    \"\"\"\n",
        "    Computes an approximation of the derivative of the samples of the signal ``x``.\n",
        "    The derivatives are calculated as the difference between each pair of adjacent samples ``x[n]``\n",
        "    and ``x[n+1]``.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : numpy.ndarray | cupy.ndarray of shape \\(N)\n",
        "        Signal, i.e. an array of ``N`` real numbers.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    : numpy.ndarray | cupy.ndarray of shape \\(N)\n",
        "        Approximation of the derivative of each sample.\n",
        "    \"\"\"\n",
        "    # if gpu available, move data to the device\n",
        "    isnumpy = isinstance(x, np.ndarray)\n",
        "    if GPU and isnumpy:\n",
        "        x = ncp.asarray(x)\n",
        "\n",
        "    # derivatives between adjacent samples\n",
        "    ders = (ncp.roll(x, -1) - x)\n",
        "    ders[-1] = 0\n",
        "    return ncp.asnumpy(ders) if GPU and isnumpy else ders\n",
        "\n",
        "\n",
        "def avg_derivatives(x :ncp.ndarray, l :int) -> ncp.ndarray:\n",
        "    \"\"\"\n",
        "    For each sample, this function computes and returns the average\n",
        "    of the ``l`` previous derivatives and the ``l`` next derivatives of the samples of the signal ``x``.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : numpy.ndarray | cupy.ndarray of shape \\(N)\n",
        "        Signal, i.e. an array of ``N`` real numbers.\n",
        "    l : int\n",
        "        Number of previous and next derivatives to average.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    : numpy.ndarray | cupy.ndarray of shape \\(N, 2)\n",
        "        Average of the ``l`` previous derivatives and the ``l`` next derivatives of each sample.\n",
        "    \"\"\"\n",
        "    # if gpu available, move data to the device\n",
        "    isnumpy = isinstance(x, np.ndarray)\n",
        "    if GPU and isnumpy:\n",
        "        x = ncp.asarray(x)\n",
        "\n",
        "    # derivatives between adjacent samples\n",
        "    ders = (ncp.roll(x, -1) - x)\n",
        "    ders[-1] = 0\n",
        "\n",
        "    # convolution to compute average derivatives\n",
        "    kernel = ncp.array([1] * l)\n",
        "    conv = ncp.convolve(ders, kernel, mode=\"full\") / l\n",
        "\n",
        "    # avg of the <l> previous and <l> next derivatives\n",
        "    avg_ders = ncp.zeros((len(x), 2))\n",
        "    avg_ders[:, 0] = ncp.roll(conv, l)[l-1:]\n",
        "    avg_ders[:, 1] = conv[l-1:]\n",
        "    return ncp.asnumpy(avg_ders) if GPU and isnumpy else avg_ders\n",
        "\n",
        "\n",
        "def detect_waves(x :ncp.ndarray, fm :int, to :int, l :int, rbf :RadialBasisFunc, mode :Literal['rand', 'threshold'], threshold :float|None=None) -> ncp.ndarray:\n",
        "    \"\"\"\n",
        "    This function, given the signal  ``x``, detects the onset, the end points and the peak between each pair of them.\n",
        "    These characteristic points are identified by taking the average of the previous and subsequent derivatives of each sample and\n",
        "    using a radial basis function to compute the probability that a sample should be included among\n",
        "    the characteristic points given its distance from those previously found.\n",
        "\n",
        "    Paramters\n",
        "    ---------\n",
        "    x : numpy.ndarray | cupy.ndarray of shape \\(N)\n",
        "        Signal, i.e. an array of ``N`` real numbers.\n",
        "    fm : int\n",
        "        Skip the first ``fm`` samples.\n",
        "    to : int\n",
        "        Skip the last ``to`` samples.\n",
        "    l : int\n",
        "        To identify onset and end points, compute the average\n",
        "        of the ``l`` previous and next derivatives of each sample.\n",
        "    rbf : RadialBasisFunc\n",
        "        Radial basis function used to compute the likelihood\n",
        "        a sample must be included among the characteristic points.\n",
        "    mode : Literal['rand', 'threshold']\n",
        "        Detection mode, two possible values are allowed:\n",
        "        - ``'rand'``: a sample is added between the points stochastically with a probability\n",
        "        that is equal to that calculated by the RBF;\n",
        "        - ``'threshold'``: a sample is added among the characteristic points if its probability,\n",
        "        computed using the RBF, is greater than ``threshold``.\n",
        "    threshold : float | None, optional\n",
        "        Threshold for the threshold detection mode, by default is ``None``.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    : numpy.ndarray | cupy.ndarray of shape \\(N, 3)\n",
        "        The onset point, the peak and the end point of each of the ``N`` waves found in ``x``.\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    : ValueError\n",
        "        If the detection mode is not valid or\n",
        "        if it is equalt to ``'threshold'`` but a threshold is not set.\n",
        "    \"\"\"\n",
        "    if mode not in ['rand', 'threshold']:\n",
        "        logger.error(\"Mode must be 'rand' or 'threshold'\")\n",
        "        raise ValueError(\"Mode must be 'rand' or 'threshold'\")\n",
        "    if mode == \"threshold\" and threshold is None:\n",
        "        logger.error(\"Threshold must be given if mode is 'threshold'\")\n",
        "        raise ValueError(\"Threshold must be given if mode is 'threshold'\")\n",
        "\n",
        "    # if gpu available, move data to the device\n",
        "    isnumpy = isinstance(x, np.ndarray)\n",
        "    if GPU and isnumpy:\n",
        "        x = ncp.asarray(x)\n",
        "\n",
        "    # avg of the <l> previous and <l> next derivatives\n",
        "    avg_ders = avg_derivatives(x, l)\n",
        "\n",
        "    # sample indeces corresponding to the start, peak and end point of each wave\n",
        "    markers = ncp.full((len(x), 3), -1, dtype=ncp.int_)\n",
        "    # number of waves found\n",
        "    counter = 0\n",
        "\n",
        "    # find onset samples\n",
        "    delta_onset = avg_ders[:, 1] - ncp.abs(avg_ders[:, 0])\n",
        "    argsort_delta_onset = ncp.argsort(delta_onset)[::-1]\n",
        "\n",
        "    for sample in argsort_delta_onset:\n",
        "        if (sample < fm) or (sample >= len(x)-to):\n",
        "            continue\n",
        "\n",
        "        if counter == 0:\n",
        "            markers[counter, 0] = sample\n",
        "            counter += 1\n",
        "            continue\n",
        "\n",
        "        # distance between <sample> and the closet marker in <markers>\n",
        "        # and thus the probability the sample should be added among markers\n",
        "        dist = ncp.min(ncp.abs(markers[:counter, 0] - sample))\n",
        "        prob = rbf.f(dist)\n",
        "\n",
        "        if (mode == \"rand\") and (ncp.random.rand(1) < prob):\n",
        "            markers[counter, 0] = sample\n",
        "            counter += 1\n",
        "        elif (mode == \"threshold\") and (prob > threshold):\n",
        "            markers[counter, 0] = sample\n",
        "            counter += 1\n",
        "\n",
        "    # free unused memory\n",
        "    del delta_onset, argsort_delta_onset\n",
        "\n",
        "    # sort the markers\n",
        "    markers = ncp.sort(markers[:counter, :], axis=0)\n",
        "    # reset counter\n",
        "    counter = 0\n",
        "\n",
        "    # find end samples\n",
        "    delta_end = avg_ders[:, 0] + ncp.abs(avg_ders[:, 1])\n",
        "    argsort_delta_end = ncp.argsort(delta_end)\n",
        "\n",
        "    for sample in argsort_delta_end:\n",
        "        # row of the corresponding onset sample\n",
        "        pos = ncp.searchsorted(markers[:, 0], ncp.array([sample])) - 1\n",
        "\n",
        "        if (sample < fm) or (sample >= len(x)-to) or (pos < 0) or (markers[pos, 2] != -1):\n",
        "            continue\n",
        "\n",
        "        if counter == 0:\n",
        "            markers[pos, 2] = sample\n",
        "            counter += 1\n",
        "            continue\n",
        "\n",
        "        # distance between <sample> and the closet marker in <markers>\n",
        "        # and thus the probability the sample should be added among markers\n",
        "        dist = ncp.min(ncp.abs(markers[:counter, 2] - sample))\n",
        "        prob = rbf.f(dist)\n",
        "\n",
        "        if (mode == \"rand\") and (ncp.random.rand(1) < prob):\n",
        "            markers[pos, 2] = sample\n",
        "            counter += 1\n",
        "        elif (mode == \"threshold\") and (prob >= threshold):\n",
        "            markers[pos, 2] = sample\n",
        "            counter += 1\n",
        "\n",
        "        if counter == len(markers):\n",
        "            break\n",
        "\n",
        "    # if an end sample is missing, set it to the last sample of the signal\n",
        "    if counter < len(markers):\n",
        "        markers[counter:, 2] = len(x) - to - 1\n",
        "\n",
        "    for i in range(len(markers)):\n",
        "        if (markers[i, 2] == -1) and (i < len(markers) - 1):\n",
        "            markers[i, 2] = argsort_delta_end[ncp.argmax((argsort_delta_end > markers[i, 0]) & (argsort_delta_end < markers[i+1, 0]))]\n",
        "\n",
        "        # find peaks\n",
        "        if markers[i,0] == markers[i,2]:\n",
        "            markers[i, 1] = markers[i, 0]\n",
        "        else:\n",
        "            markers[i, 1] = ncp.argmax(x[markers[i,0]:markers[i,2]]) + markers[i,0]\n",
        "\n",
        "    # free unused memory\n",
        "    del delta_end, argsort_delta_end\n",
        "\n",
        "    return ncp.asnumpy(markers) if GPU and isnumpy else markers"
      ],
      "metadata": {
        "id": "I4jEiFUmp_-z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two examples:"
      ],
      "metadata": {
        "id": "vr5VeayidpzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# frequency\n",
        "f = 12\n",
        "# number of samples\n",
        "N = 1000\n",
        "\n",
        "# original signal\n",
        "n = np.arange(N)\n",
        "x = np.sinc(2 * np.pi * f * np.linspace(-0.5, 0.5, N, endpoint=False))\n",
        "\n",
        "# compute dft and reconstruct the signal\n",
        "c1 = dft_l1(x, K=1000)\n",
        "c2 = dft_l1(x, K=501)\n",
        "c3 = dft_l1(x, K=10)\n",
        "\n",
        "xk1 = idft_l1(c1, N=N, onlyreal=True)\n",
        "xk2 = idft_l1(c2, N=N, onlyreal=True)\n",
        "xk3 = idft_l1(c3, N=N, onlyreal=True)\n",
        "\n",
        "# plot the results\n",
        "fig, axs = plt.subplots(2, 2, figsize=(16, 8))\n",
        "fig.suptitle(\"Sinc function: original vs reconstructed signal using L1-DFT/IDFT\")\n",
        "\n",
        "axs[0, 0].plot(n, x, c=\"blue\", label=\"Original signal\")\n",
        "axs[0, 0].set(xlabel=\"Sample idxs: n\", ylabel=\"x[n]\")\n",
        "axs[0, 0].legend(loc=\"upper left\")\n",
        "\n",
        "axs[1, 0].plot(n, xk1, c=\"orange\", label=\"Recon. signal K=1000\")\n",
        "axs[1, 0].plot(n, xk2, c=\"magenta\", label=\"Recon. signal K=501\")\n",
        "axs[1, 0].plot(n, xk3, c=\"green\", label=\"Recon. signal K=10\")\n",
        "axs[1, 0].set(xlabel=\"Sample idxs: n\", ylabel=\"xk[n]\")\n",
        "axs[1, 0].legend(loc=\"upper left\")\n",
        "\n",
        "axs[0, 1].plot(n[:501], np.abs(c1[:501]), c=\"deepskyblue\", label=\"Fourier coeff.\")\n",
        "axs[0, 1].set(xlabel=\"Coefficients: k\", ylabel=\"Magnitude X[k]\")\n",
        "axs[0, 1].legend(loc=\"upper right\")\n",
        "\n",
        "axs[1, 1].plot(n[:501], np.angle(c1[:501]), c=\"deepskyblue\", label=\"Fourier coeff.\")\n",
        "axs[1, 1].set(xlabel=\"Coefficients: k\", ylabel=\"Phase X[k]\")\n",
        "axs[1, 1].legend(loc=\"upper right\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "67Ag3uSURVVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of samples\n",
        "N = 1000\n",
        "\n",
        "# original signal\n",
        "n = np.arange(N)\n",
        "x = np.array([0] * (N//5) + [1] * (3*N//5) + [0] * (N//5))\n",
        "\n",
        "# compute dft and reconstruct the signal\n",
        "c1 = dft_l1(x, K=10, max_iters=10)\n",
        "c2 = np.fft.fft(x) * np.array([1] * (10) + [0] * (N-19) + [1] * (9))\n",
        "\n",
        "xk1 = idft_l1(c1, N=N, onlyreal=True)\n",
        "xk2 = np.real(np.fft.ifft(c2))\n",
        "\n",
        "# plot the results\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.title(\"Square function: L1-DFT/IDFT vs L2-DFT/IDFT\")\n",
        "plt.plot(n, x, c=\"blue\", label=\"Original signal\")\n",
        "plt.plot(n, xk1, c=\"orange\", label=\"Recon. signal L1-I/DFT K=R=10\")\n",
        "plt.plot(n, xk2, c=\"red\", label=\"Recon. signal L2-I/DFT K=10\")\n",
        "plt.xlabel(\"Sample idxs: n\")\n",
        "plt.ylabel(\"xk[n]\")\n",
        "plt.legend(loc=\"lower center\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jh5L3ZoqV6la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ECG decomposition:"
      ],
      "metadata": {
        "id": "OcyTtlJpdu-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "   return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "deRR272goXKY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download dataset\n",
        "!wget -r -N -c -np https://physionet.org/files/ludb/1.0.1/\n",
        "DATAPATH = \"/content/physionet.org/files/ludb/1.0.1/data/\""
      ],
      "metadata": {
        "id": "a22NCpEZUxGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ECG and lead to consider:\n",
        "id = \"154\"  # @param {type: \"string\"}\n",
        "lead_name = \"V3\"  # @param ['AVF','AVL','AVR','I','II','III','V1','V2','V3','V4','V5','V6']\n",
        "# @markdown L1-DFT parameters:\n",
        "K = 64  # @param {type: \"integer\"}\n",
        "max_iters = 50  # @param {type: \"integer\"}\n",
        "eps = 1e-5  # @param {type: \"number\"}\n",
        "# @markdown Wave detector parameters:\n",
        "bpm = 80 # @param {type: \"integer\"}\n",
        "prob = 0.63  # @param {type: \"number\"}\n",
        "fm = 100  # @param {type: \"integer\"}\n",
        "to = 100  # @param {type: \"integer\"}\n",
        "l = 40  # @param {type: \"integer\"}\n",
        "mode = \"threshold\"  # @param ['threshold', 'rand']\n",
        "threshold = 0.60  # @param {type: \"number\"}\n",
        "# @markdown ---\n",
        "\n",
        "# ECG signal\n",
        "ecg = ECG(DATAPATH, id)\n",
        "lead = ECG.Lead[lead_name]\n",
        "\n",
        "n = np.arange(ecg.size)\n",
        "x = ecg.get_p_signal(lead)\n",
        "\n",
        "# Fourier coeff. and recon. ECG\n",
        "c = dft_l1(x, K=K, max_iters=max_iters, eps=eps)\n",
        "xk = idft_l1(c, N=ecg.size, onlyreal=True)\n",
        "\n",
        "ders = derivatives(xk)\n",
        "\n",
        "sigma = GaussianRBF.compute_sigma(prob, ecg.fs // (bpm / 60))\n",
        "logger.info(f\"Gaussian RBF -> ~ 63% prob. at dist=1/sigma={1//sigma}\")\n",
        "\n",
        "# predicted markers\n",
        "pred_markers = detect_waves(\n",
        "    xk,\n",
        "    fm=fm,\n",
        "    to=to,\n",
        "    l=l,\n",
        "    rbf=GaussianRBF(sigma=sigma),\n",
        "    mode=mode,\n",
        "    threshold=threshold\n",
        ")\n",
        "\n",
        "# expected markers\n",
        "markers = ecg.t_waves(lead)\n",
        "\n",
        "print(f\"Expected markers ({len(markers)}):\")\n",
        "print(markers)\n",
        "print(f\"Predicted markers ({len(pred_markers)}):\")\n",
        "print(pred_markers)"
      ],
      "metadata": {
        "id": "WY9y4TMTsWcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(60, 10))\n",
        "\n",
        "plt.axhline(y=0, c=\"dimgrey\", linestyle=\"dotted\", alpha=0.4)\n",
        "plt.axvline(x=fm, c=\"red\", linestyle=\"dashed\")\n",
        "plt.axvline(x=len(x)-to, c=\"red\", linestyle=\"dashed\")\n",
        "\n",
        "plt.plot(n, x, c=\"black\", label=\"Orig. signal\")\n",
        "plt.plot(n, xk, c=\"blue\", label=\"Recon. signal\")\n",
        "\n",
        "plt.plot(n, 10*ders, c=\"yellow\", label=\"Derivatives\", alpha=0.6)\n",
        "\n",
        "for i, marker in enumerate(markers):\n",
        "    plt.axvline(x=marker[0], c=\"purple\", linestyle=\"dashdot\", label=\"Onset\" if i == 0 else \"_nolegend_\")\n",
        "    plt.axvline(x=marker[1], c=\"darkorange\", linestyle=\"dashdot\", label=\"Peak\" if i == 0 else \"_nolegend_\")\n",
        "    plt.axvline(x=marker[2], c=\"magenta\", linestyle=\"dashdot\", label=\"End\" if i == 0 else \"_nolegend_\")\n",
        "\n",
        "for i, pred_marker in enumerate(pred_markers):\n",
        "    plt.axvline(x=pred_marker[0], c=\"purple\", label=\"Pred. onset\" if i == 0 else \"_nolegend_\")\n",
        "    plt.axvline(x=pred_marker[1], c=\"darkorange\", label=\"Pred. peak\" if i == 0 else \"_nolegend_\")\n",
        "    plt.axvline(x=pred_marker[2], c=\"magenta\", label=\"Pred. end\" if i == 0 else \"_nolegend_\")\n",
        "\n",
        "#plt.xlim(1100, 3100)\n",
        "plt.legend(loc=\"lower center\", ncol=3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lyTO9Tz2Ayl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model quality assessment:\n",
        "The following code analyses all available ECGs and estimates the quality of the model by assessing the average distance between predicted and expected markers."
      ],
      "metadata": {
        "id": "BB5mUoU1WEQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lead's id\n",
        "leads_id = {lead:id for id, lead in enumerate(ECG.Lead)}\n",
        "\n",
        "# number of ECGs\n",
        "N = 200\n",
        "\n",
        "# avg distance between expected and predicted labels for each ecg and lead\n",
        "avg_dist = np.zeros((len(leads_id), N, 3))\n",
        "\n",
        "for i in range(1, 201):\n",
        "    ecg = ECG(DATAPATH, str(i))\n",
        "\n",
        "    for lead in ecg.leads:\n",
        "        # signal\n",
        "        x = ecg.get_p_signal(lead)\n",
        "        # heart rate\n",
        "        hr = ecg.get_mean_hr(lead)\n",
        "        # expected markers\n",
        "        markers = ecg.t_waves(lead)\n",
        "\n",
        "        # Fourier coeff. and recon. signal\n",
        "        c = dft_l1(x, K=64, max_iters=10, eps=1e-05)\n",
        "        xk = idft_l1(c, N=ecg.size, onlyreal=True)\n",
        "\n",
        "        try:\n",
        "            # predicetd markers\n",
        "            pred_markers = detect_waves(\n",
        "                xk,\n",
        "                fm=100,\n",
        "                to=100,\n",
        "                l=40,\n",
        "                rbf=GaussianRBF(sigma=1/hr),\n",
        "                mode=\"threshold\",\n",
        "                threshold=0.60\n",
        "            )\n",
        "\n",
        "            # closest predicted marker to each expected marker\n",
        "            matched_markers_idxs = np.argmin(\n",
        "                np.sum(np.abs(markers[:, None, :] - pred_markers), axis=-1),\n",
        "                axis=-1\n",
        "            )\n",
        "\n",
        "            # update average distance\n",
        "            avg_dist[leads_id[lead], i-1] = np.mean(np.abs(markers - pred_markers[matched_markers_idxs]),  axis=0)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"ECG:{i}, lead:{lead} ->  HR:{hr}, exception:{e}\")\n",
        "            avg_dist[leads_id[lead], i-1] = np.array([0, 0 , 0])\n",
        "\n",
        "    logger.info(f\"ECG {i} done\")\n",
        "\n",
        "avg_dist"
      ],
      "metadata": {
        "id": "A9AARmrMRco2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra"
      ],
      "metadata": {
        "id": "Q52i-H-2cNjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Read/Save the variables --\n",
        "import pickle\n",
        "\n",
        "def write_var(variable, filename):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(variable, f)\n",
        "\n",
        "def read_var(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        variable = pickle.load(f)\n",
        "    return variable\n",
        "\n",
        "\n",
        "write_var(avg_dist, \"avg_dist.pkl\")\n",
        "#  = read_var(\".pkl\")"
      ],
      "metadata": {
        "id": "LVC6gLPpcOjp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}